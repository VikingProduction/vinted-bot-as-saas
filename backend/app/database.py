"""
Configuration de base de donn√©es avec SQLAlchemy
"""
from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.pool import QueuePool
import redis
from typing import Generator

from .config import settings, logger

# Configuration moteur SQLAlchemy
engine = create_engine(
    settings.database_url,
    poolclass=QueuePool,
    pool_size=20,
    max_overflow=30,
    pool_pre_ping=True,
    pool_recycle=3600,
    echo=settings.debug,  # Log SQL queries en mode debug
    echo_pool=settings.debug,
    connect_args={
        "charset": "utf8mb4",
        "connect_timeout": 30,
        "read_timeout": 30,
        "write_timeout": 30,
    }
)

# Session factory
SessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine,
    expire_on_commit=False
)

# Base pour les mod√®les
Base = declarative_base()

# Metadata pour les migrations
metadata = MetaData()

# Configuration Redis
redis_client = redis.from_url(
    settings.redis_url,
    password=settings.redis_password if settings.redis_password else None,
    decode_responses=True,
    retry_on_timeout=True,
    socket_connect_timeout=5,
    socket_timeout=5,
    health_check_interval=30
)


def get_db() -> Generator[Session, None, None]:
    """
    G√©n√©rateur de session de base de donn√©es pour l'injection de d√©pendances FastAPI
    """
    db = SessionLocal()
    try:
        yield db
    except Exception as e:
        logger.error("Erreur base de donn√©es", error=str(e))
        db.rollback()
        raise
    finally:
        db.close()


def get_redis() -> redis.Redis:
    """
    Retourne le client Redis
    """
    return redis_client


def init_db():
    """
    Initialise la base de donn√©es en cr√©ant toutes les tables
    """
    try:
        # Import de tous les mod√®les pour cr√©er les tables
        from .models import user, filter, alert, subscription
        
        Base.metadata.create_all(bind=engine)
        logger.info("‚úÖ Base de donn√©es initialis√©e")
        
    except Exception as e:
        logger.error("‚ùå Erreur initialisation base de donn√©es", error=str(e))
        raise


def check_db_connection():
    """
    V√©rifie la connexion √† la base de donn√©es
    """
    try:
        db = SessionLocal()
        db.execute("SELECT 1")
        db.close()
        return True
    except Exception as e:
        logger.error("‚ùå Connexion base de donn√©es √©chou√©e", error=str(e))
        return False


def check_redis_connection():
    """
    V√©rifie la connexion √† Redis
    """
    try:
        redis_client.ping()
        return True
    except Exception as e:
        logger.error("‚ùå Connexion Redis √©chou√©e", error=str(e))
        return False


# Utilitaires pour les transactions
class DatabaseManager:
    """Gestionnaire de base de donn√©es avec gestion automatique des transactions"""
    
    def __init__(self):
        self.db = None
    
    def __enter__(self):
        self.db = SessionLocal()
        return self.db
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            self.db.rollback()
            logger.error(
                "Transaction rollback", 
                error=str(exc_val), 
                type=str(exc_type)
            )
        else:
            try:
                self.db.commit()
            except Exception as e:
                self.db.rollback()
                logger.error("Erreur commit transaction", error=str(e))
                raise
        finally:
            self.db.close()


# Cache Redis avec helpers
class CacheManager:
    """Gestionnaire de cache Redis avec helpers"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
    
    def get(self, key: str):
        """R√©cup√®re une valeur du cache"""
        try:
            return self.redis.get(key)
        except Exception as e:
            logger.warning(f"Erreur lecture cache {key}", error=str(e))
            return None
    
    def set(self, key: str, value: str, expire: int = 3600):
        """Stocke une valeur dans le cache"""
        try:
            return self.redis.setex(key, expire, value)
        except Exception as e:
            logger.warning(f"Erreur √©criture cache {key}", error=str(e))
            return False
    
    def delete(self, key: str):
        """Supprime une cl√© du cache"""
        try:
            return self.redis.delete(key)
        except Exception as e:
            logger.warning(f"Erreur suppression cache {key}", error=str(e))
            return False
    
    def exists(self, key: str):
        """V√©rifie si une cl√© existe dans le cache"""
        try:
            return self.redis.exists(key)
        except Exception as e:
            logger.warning(f"Erreur v√©rification cache {key}", error=str(e))
            return False
    
    def increment(self, key: str, amount: int = 1):
        """Incr√©mente une valeur num√©rique"""
        try:
            return self.redis.incrby(key, amount)
        except Exception as e:
            logger.warning(f"Erreur incr√©mentation cache {key}", error=str(e))
            return None
    
    def get_user_cache_key(self, user_id: int, suffix: str = ""):
        """G√©n√®re une cl√© de cache pour un utilisateur"""
        return f"user:{user_id}:{suffix}" if suffix else f"user:{user_id}"
    
    def get_filter_cache_key(self, filter_id: int, suffix: str = ""):
        """G√©n√®re une cl√© de cache pour un filtre"""
        return f"filter:{filter_id}:{suffix}" if suffix else f"filter:{filter_id}"


# Instance globale du gestionnaire de cache
cache_manager = CacheManager(redis_client)


# Utilitaires pour les requ√™tes communes
class QueryHelper:
    """Helpers pour requ√™tes communes"""
    
    @staticmethod
    def get_active_users(db: Session):
        """R√©cup√®re les utilisateurs actifs"""
        from .models.user import User
        return db.query(User).filter(User.is_active == True).all()
    
    @staticmethod
    def get_user_active_filters(db: Session, user_id: int):
        """R√©cup√®re les filtres actifs d'un utilisateur"""
        from .models.filter import VintedFilter
        return db.query(VintedFilter).filter(
            VintedFilter.user_id == user_id,
            VintedFilter.is_active == True
        ).all()
    
    @staticmethod
    def get_recent_alerts(db: Session, user_id: int, limit: int = 50):
        """R√©cup√®re les alertes r√©centes d'un utilisateur"""
        from .models.alert import Alert
        return db.query(Alert).filter(
            Alert.user_id == user_id
        ).order_by(Alert.created_at.desc()).limit(limit).all()
    
    @staticmethod
    def get_user_subscription(db: Session, user_id: int):
        """R√©cup√®re l'abonnement actif d'un utilisateur"""
        from .models.subscription import Subscription
        return db.query(Subscription).filter(
            Subscription.user_id == user_id,
            Subscription.status == 'active'
        ).first()


# Instance globale des helpers
query_helper = QueryHelper()


# √âv√©nements de cycle de vie de l'application
async def startup_database():
    """Initialisation de la base de donn√©es au d√©marrage"""
    logger.info("üîÑ Initialisation base de donn√©es...")
    
    # V√©rification connexion MySQL
    if not check_db_connection():
        raise Exception("Connexion MySQL impossible")
    
    # V√©rification connexion Redis  
    if not check_redis_connection():
        raise Exception("Connexion Redis impossible")
    
    # Initialisation des tables
    init_db()
    
    logger.info("‚úÖ Base de donn√©es pr√™te")


async def shutdown_database():
    """Nettoyage au shutdown"""
    logger.info("üîÑ Fermeture connexions base de donn√©es...")
    
    try:
        # Fermeture pool de connexions
        engine.dispose()
        
        # Fermeture connexions Redis
        redis_client.close()
        
        logger.info("‚úÖ Connexions ferm√©es proprement")
        
    except Exception as e:
        logger.error("‚ùå Erreur fermeture connexions", error=str(e))


# D√©corateur pour les op√©rations avec retry
import functools
import time
from typing import Callable, Any

def db_retry(max_attempts: int = 3, delay: float = 1.0):
    """
    D√©corateur pour retry automatique des op√©rations base de donn√©es
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            last_exception = None
            
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    logger.warning(
                        f"Tentative {attempt + 1}/{max_attempts} √©chou√©e",
                        function=func.__name__,
                        error=str(e)
                    )
                    
                    if attempt < max_attempts - 1:
                        time.sleep(delay * (2 ** attempt))  # Backoff exponentiel
            
            # Si toutes les tentatives √©chouent
            logger.error(
                f"Toutes les tentatives √©chou√©es pour {func.__name__}",
                error=str(last_exception)
            )
            raise last_exception
        
        return wrapper
    return decorator